fastapi==0.104.1
uvicorn[standard]==0.24.0
numpy==1.26.2
scipy==1.10.1
pandas==2.1.4
qdrant-client==1.7.0
deepchecks==0.17.5
python-dotenv==1.0.0
requests==2.31.0
prometheus-client==0.19.0
pydantic==2.5.2
# Evaluation metrics
ragas>=0.1.0
rouge-score>=0.1.2
bert-score>=0.3.13
nltk>=3.8.1
sentence-transformers>=2.2.2
# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
# LM Evaluation Harness
lm-eval>=0.4.0

