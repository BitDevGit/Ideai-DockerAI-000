global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  # The prometheus server itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Ollama LLM Runtime
  # Note: Ollama doesn't expose native Prometheus metrics
  # A custom exporter would be needed for full metrics
  - job_name: 'ollama'
    static_configs:
      - targets: ['ollama-llm:11434']
    metrics_path: /api/metrics
    scrape_interval: 30s

  # Python RAG Backend
  - job_name: 'python-rag'
    metrics_path: /metrics
    static_configs:
      - targets: ['python-rag:8000']

  # Rust/Wasm Compute Backend
  - job_name: 'rust-wasm-compute'
    metrics_path: /metrics
    static_configs:
      - targets: ['rust-wasm-compute:8080']

  # Grafana
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']


